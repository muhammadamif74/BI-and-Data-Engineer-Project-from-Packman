-- End-to-End Data Pipeline Project with Metabase --
This project demonstrates how to build an end-to-end data pipeline using Python, PostgreSQL, Docker, and Metabase. 
It was originally developed for educational purposes (e.g., Twitter Thread for Pacmann) and can be adapted to suit other datasets or use cases.

a. Project Structure 

.
├── assets/
│   └── workflow.png         # Visual of pipeline flow
├── data/
│   ├── california.csv       # Sample car sales data by state
│   ├── florida.csv
│   ├── georgia.csv
│   ├── pennsylvania.csv
│   └── texas.csv
├── data_pipeline.py         # Python script for ETL pipeline
├── docker-compose.yml       # Docker config for Postgres & Metabase
├── requirements.txt         # Python dependencies
└── README.md                # This file

b.  Tools & Technologies

  -Python – For data processing (ETL)
  -Pandas – Data manipulation
  -PostgreSQL – Relational database to store cleaned data
  -Docker – Containerization for PostgreSQL and Metabase
  -Metabase – Open-source BI tool for dashboarding

c.Dataset
The dataset used is car sales data from five U.S. states:

  -California
  -Florida
  -Georgia
  -Pennsylvania
  -Texas

Each CSV file contains vehicle listings with attributes such as brand, year, selling_price, etc.

c. Step-by-Step Tutorial
   This use a terminal CMD (Command Prompt)

  1. Clone the repository

    git clone https://github.com/yourusername/your-repo-name.git
    cd your-repo-name

  2. Install Python dependencies

    python -m venv venv
    #On Windows: venv\Scripts\activate
    pip install -r requirements.txt

  3. Start Docker Services (PostgreSQL + Metabase)

    docker compose up -d --build
  
    This will spin up:

    -PostgreSQL on port 5434
    -Metabase on port 3000

    Check running containers:
    docker ps

  4. Run the Data Pipeline
      Execute the ETL script to:
      -Load and combine CSVs
      -Filter data where selling_price > 14000
      -Load the result into the PostgreSQL database

      python data_pipeline.py

  5. Open Metabase
  Access the Metabase UI at:

  http://localhost:3000
  On first use, create an admin account and add a new PostgreSQL database with:
  
  Field	Value
  Host          :	host.docker.internal 
  Port	        : 5434
  Database Name : db_sales
  Username	    : postgres
  Password	    : mypassword
  
  6. Visualize the Data
  Explore the uploaded table inside Metabase.
  
  Build custom dashboards using filters like:
  
  - Average selling price per brand/state
  - Total vehicles by year
  - Price distribution charts

d.Customization
  We can easily:
  
  - Replace the data source with our own (CSV, JSON, APIs, etc.)
  - Add more transformation logic in data_pipeline.py
  - Extend to use tools like Airflow or dbt for orchestration


